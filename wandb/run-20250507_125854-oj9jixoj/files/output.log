Total parameters: 249221
Epoch 1/50
----------
  0%|[34m                                                                                                                                                                       [39m| 0/52 [00:00<?, ?it/s]C:\Users\ASUS\anaconda3\envs\gpu_torch_5\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)










100%|[34m██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████[39m| 52/52 [00:24<00:00,  2.15it/s]

 77%|[32m█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    [39m| 27/35 [00:03<00:00,  8.05it/s]
Total time:28.43460774421692
Loss: 5.366641828941576
Validation Loss: 5.674114327864213
HGR Accuracy: tensor(0.0903, device='cuda:0')
ID Accuracy: tensor(0.0976, device='cuda:0')
Validation HGR Accuracy: tensor(0.0909, device='cuda:0')
Validation ID Accuracy: tensor(0.1000, device='cuda:0')
Epoch 2/50
100%|[32m██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████[39m| 35/35 [00:04<00:00,  8.23it/s]












100%|[34m██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████[39m| 52/52 [00:25<00:00,  2.06it/s]

 80%|[32m██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               [39m| 28/35 [00:03<00:00,  7.22it/s]
Total time:30.019059658050537
Loss: 5.1562139776981235
Validation Loss: 4.7004805200750175
HGR Accuracy: tensor(0.0879, device='cuda:0')
ID Accuracy: tensor(0.1006, device='cuda:0')
Validation HGR Accuracy: tensor(0.0909, device='cuda:0')
Validation ID Accuracy: tensor(0.1000, device='cuda:0')
Epoch 3/50
100%|[32m██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████[39m| 35/35 [00:04<00:00,  7.37it/s]
 10%|[34m███████████████▎                                                                                                                                               [39m| 5/52 [00:02<00:24,  1.89it/s]
Traceback (most recent call last):
  File "D:\IIT Delhi\Projects\Adversarial games\Experimentation\codeBase\trainer.py", line 85, in <module>
    train_metrics, val_metrics = train_val(train_dataLoader,
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\IIT Delhi\Projects\Adversarial games\Experimentation\codeBase\epoch.py", line 149, in train_val
    loss_hgr_train_curr, loss_id_train_curr, loss_icgd_train_curr, loss_train_curr, acc_hgr_train_curr, acc_id_train_curr = train_epoch(train_loader,
                                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\IIT Delhi\Projects\Adversarial games\Experimentation\codeBase\epoch.py", line 42, in train_epoch
    loss_icgd_batch = obj_icgd(y_hgr,y_id,f_theta) # ICGD Loss
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\anaconda3\envs\gpu_torch_5\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ASUS\anaconda3\envs\gpu_torch_5\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\IIT Delhi\Projects\Adversarial games\Experimentation\codeBase\icgd.py", line 62, in forward
    id_mask = self.get_IDmask(y_id) # ID mask, shape -> (B,B)
              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\IIT Delhi\Projects\Adversarial games\Experimentation\codeBase\icgd.py", line 33, in get_IDmask
    id_mask_dist = torch.logical_not(torch.eye(B).to(torch.bool)).to(device_id,dtype=torch.float32) # Except diagonal entries everything turned high
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt